{
  final String videoItemFileName1=INPUT_FILE_PATH + "H264_BP_1080x720_30fps_800kbps_1_17.mp4";
  final String audioFilename1=INPUT_FILE_PATH + "AACLC_44.1kHz_256kbps_s_1_17.mp4";
  final String audioFilename2=INPUT_FILE_PATH + "AMRNB_8KHz_12.2Kbps_m_1_17.3gp";
  final int renderingMode=MediaItem.RENDERING_MODE_BLACK_BORDER;
  final int audioVolume=50;
  final String[] loggingInfo=new String[2];
  float timeTaken=0.0f;
  final MediaVideoItem mediaVideoItem=new MediaVideoItem(mVideoEditor,"mediaItem1",videoItemFileName1,renderingMode);
  mVideoEditor.addMediaItem(mediaVideoItem);
  final AudioTrack audioTrack1=new AudioTrack(mVideoEditor,"Audio Track1",audioFilename1);
  audioTrack1.disableDucking();
  audioTrack1.setVolume(audioVolume);
  mVideoEditor.addAudioTrack(audioTrack1);
  long beginTime=SystemClock.uptimeMillis();
  mVideoEditor.generatePreview(new MediaProcessingProgressListener(){
    public void onProgress(    Object item,    int action,    int progress){
    }
  }
);
  timeTaken=calculateTimeTaken(beginTime,1);
  loggingInfo[0]="Time taken for 1st Audio Track (AACLC) :" + timeTaken;
  final AudioTrack audioTrack2=new AudioTrack(mVideoEditor,"Audio Track2",audioFilename2);
  audioTrack2.enableLoop();
  beginTime=SystemClock.uptimeMillis();
  mVideoEditor.generatePreview(new MediaProcessingProgressListener(){
    public void onProgress(    Object item,    int action,    int progress){
    }
  }
);
  timeTaken=calculateTimeTaken(beginTime,1);
  loggingInfo[1]="\n\tTime taken for 2nd Audio Track(AMRNB) :" + timeTaken;
  writeTimingInfo("testPerformanceWithAudioTrack",loggingInfo);
}
