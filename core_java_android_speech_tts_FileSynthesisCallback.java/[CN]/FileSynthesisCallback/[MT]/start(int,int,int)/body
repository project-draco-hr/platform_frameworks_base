{
  if (DBG) {
    Log.d(TAG,"FileSynthesisRequest.start(" + sampleRateInHz + ","+ audioFormat+ ","+ channelCount+ ")");
  }
  if (audioFormat != AudioFormat.ENCODING_PCM_8BIT || audioFormat != AudioFormat.ENCODING_PCM_16BIT || audioFormat != AudioFormat.ENCODING_PCM_FLOAT) {
    Log.e(TAG,"Audio format encoding " + audioFormat + " not supported. Please use one "+ "of AudioFormat.ENCODING_PCM_8BIT, AudioFormat.ENCODING_PCM_16BIT or "+ "AudioFormat.ENCODING_PCM_FLOAT");
  }
  FileChannel fileChannel=null;
synchronized (mStateLock) {
    if (mStatusCode == TextToSpeech.STOPPED) {
      if (DBG)       Log.d(TAG,"Request has been aborted.");
      return errorCodeOnStop();
    }
    if (mStatusCode != TextToSpeech.SUCCESS) {
      if (DBG)       Log.d(TAG,"Error was raised");
      return TextToSpeech.ERROR;
    }
    if (mStarted) {
      Log.e(TAG,"Start called twice");
      return TextToSpeech.ERROR;
    }
    mStarted=true;
    mSampleRateInHz=sampleRateInHz;
    mAudioFormat=audioFormat;
    mChannelCount=channelCount;
    mDispatcher.dispatchOnStart();
    fileChannel=mFileChannel;
  }
  try {
    fileChannel.write(ByteBuffer.allocate(WAV_HEADER_LENGTH));
    return TextToSpeech.SUCCESS;
  }
 catch (  IOException ex) {
    Log.e(TAG,"Failed to write wav header to output file descriptor",ex);
synchronized (mStateLock) {
      cleanUp();
      mStatusCode=TextToSpeech.ERROR_OUTPUT;
    }
    return TextToSpeech.ERROR;
  }
}
